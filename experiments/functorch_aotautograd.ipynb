{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from functorch import vmap, grad\n",
    "from torch.fx import symbolic_trace\n",
    "from functorch.compile import aot_function, ts_compile, make_boxed_func\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lennard_jones(r: torch.Tensor, epsilon: float = 1.0, sigma: float = 1.0):\n",
    "    \"\"\" \"\"\"\n",
    "    sigma = torch.tensor(sigma, device=r.device)\n",
    "    epsilon = torch.tensor(epsilon, device=r.device)\n",
    "    u = (sigma / r) ** 2\n",
    "    v = u * u * u\n",
    "    return torch.tensor(4.0, device=r.device) * epsilon * (v * v - v)\n",
    "\n",
    "\n",
    "def dlj_dr(r: torch.Tensor, epsilon: float = 1.0, sigma: float = 1.0):\n",
    "    \"\"\"\"\"\"\n",
    "    u = -4.0 * epsilon * sigma / r**2\n",
    "    v = sigma / r\n",
    "    return u * (12 * v**11 - 6 * v**5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"407.731094pt\" height=\"304.837078pt\" viewBox=\"0 0 407.731094 304.837078\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2023-03-27T15:34:11.348927</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.7.0, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 304.837078 \nL 407.731094 304.837078 \nL 407.731094 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 43.411094 277.491141 \nL 400.531094 277.491141 \nL 400.531094 11.379141 \nL 43.411094 11.379141 \nz\n\" style=\"fill: #eaeaf2\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path d=\"M 59.643821 277.491141 \nL 59.643821 11.379141 \n\" clip-path=\"url(#pb2608a921a)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0.5 -->\n      <g style=\"fill: #262626\" transform=\"translate(50.897102 295.349422) scale(0.11 -0.11)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <path d=\"M 124.57473 277.491141 \nL 124.57473 11.379141 \n\" clip-path=\"url(#pb2608a921a)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_2\">\n      <!-- 1.0 -->\n      <g style=\"fill: #262626\" transform=\"translate(115.828011 295.349422) scale(0.11 -0.11)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <path d=\"M 189.505639 277.491141 \nL 189.505639 11.379141 \n\" clip-path=\"url(#pb2608a921a)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_3\">\n      <!-- 1.5 -->\n      <g style=\"fill: #262626\" transform=\"translate(180.75892 295.349422) scale(0.11 -0.11)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <path d=\"M 254.436548 277.491141 \nL 254.436548 11.379141 \n\" clip-path=\"url(#pb2608a921a)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_4\">\n      <!-- 2.0 -->\n      <g style=\"fill: #262626\" transform=\"translate(245.68983 295.349422) scale(0.11 -0.11)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <path d=\"M 319.367457 277.491141 \nL 319.367457 11.379141 \n\" clip-path=\"url(#pb2608a921a)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_5\">\n      <!-- 2.5 -->\n      <g style=\"fill: #262626\" transform=\"translate(310.620739 295.349422) scale(0.11 -0.11)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <path d=\"M 384.298366 277.491141 \nL 384.298366 11.379141 \n\" clip-path=\"url(#pb2608a921a)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_6\">\n      <!-- 3.0 -->\n      <g style=\"fill: #262626\" transform=\"translate(375.551648 295.349422) scale(0.11 -0.11)\">\n       <defs>\n        <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \nQ 3050 2419 3304 2112 \nQ 3559 1806 3559 1356 \nQ 3559 666 3084 287 \nQ 2609 -91 1734 -91 \nQ 1441 -91 1130 -33 \nQ 819 25 488 141 \nL 488 750 \nQ 750 597 1062 519 \nQ 1375 441 1716 441 \nQ 2309 441 2620 675 \nQ 2931 909 2931 1356 \nQ 2931 1769 2642 2001 \nQ 2353 2234 1838 2234 \nL 1294 2234 \nL 1294 2753 \nL 1863 2753 \nQ 2328 2753 2575 2939 \nQ 2822 3125 2822 3475 \nQ 2822 3834 2567 4026 \nQ 2313 4219 1838 4219 \nQ 1578 4219 1281 4162 \nQ 984 4106 628 3988 \nL 628 4550 \nQ 988 4650 1302 4700 \nQ 1616 4750 1894 4750 \nQ 2613 4750 3031 4423 \nQ 3450 4097 3450 3541 \nQ 3450 3153 3228 2886 \nQ 3006 2619 2597 2516 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-33\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <path d=\"M 43.411094 277.491141 \nL 400.531094 277.491141 \n\" clip-path=\"url(#pb2608a921a)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_7\">\n      <!-- −2.5 -->\n      <g style=\"fill: #262626\" transform=\"translate(7.2 281.670281) scale(0.11 -0.11)\">\n       <defs>\n        <path id=\"DejaVuSans-2212\" d=\"M 678 2272 \nL 4684 2272 \nL 4684 1741 \nL 678 1741 \nL 678 2272 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"83.789062\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"147.412109\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"179.199219\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <path d=\"M 43.411094 239.475141 \nL 400.531094 239.475141 \n\" clip-path=\"url(#pb2608a921a)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_8\">\n      <!-- −2.0 -->\n      <g style=\"fill: #262626\" transform=\"translate(7.2 243.654281) scale(0.11 -0.11)\">\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"83.789062\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"147.412109\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"179.199219\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <path d=\"M 43.411094 201.459141 \nL 400.531094 201.459141 \n\" clip-path=\"url(#pb2608a921a)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_9\">\n      <!-- −1.5 -->\n      <g style=\"fill: #262626\" transform=\"translate(7.2 205.638281) scale(0.11 -0.11)\">\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-31\" x=\"83.789062\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"147.412109\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"179.199219\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <path d=\"M 43.411094 163.443141 \nL 400.531094 163.443141 \n\" clip-path=\"url(#pb2608a921a)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_10\">\n      <!-- −1.0 -->\n      <g style=\"fill: #262626\" transform=\"translate(7.2 167.622281) scale(0.11 -0.11)\">\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-31\" x=\"83.789062\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"147.412109\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"179.199219\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <path d=\"M 43.411094 125.427141 \nL 400.531094 125.427141 \n\" clip-path=\"url(#pb2608a921a)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_11\">\n      <!-- −0.5 -->\n      <g style=\"fill: #262626\" transform=\"translate(7.2 129.606281) scale(0.11 -0.11)\">\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"83.789062\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"147.412109\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"179.199219\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_12\">\n      <path d=\"M 43.411094 87.411141 \nL 400.531094 87.411141 \n\" clip-path=\"url(#pb2608a921a)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.0 -->\n      <g style=\"fill: #262626\" transform=\"translate(16.417656 91.590281) scale(0.11 -0.11)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_13\">\n      <path d=\"M 43.411094 49.395141 \nL 400.531094 49.395141 \n\" clip-path=\"url(#pb2608a921a)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_13\">\n      <!-- 0.5 -->\n      <g style=\"fill: #262626\" transform=\"translate(16.417656 53.574281) scale(0.11 -0.11)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_14\">\n      <path d=\"M 43.411094 11.379141 \nL 400.531094 11.379141 \n\" clip-path=\"url(#pb2608a921a)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n     </g>\n     <g id=\"text_14\">\n      <!-- 1.0 -->\n      <g style=\"fill: #262626\" transform=\"translate(16.417656 15.558281) scale(0.11 -0.11)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"PolyCollection_1\"/>\n   <g id=\"PolyCollection_2\"/>\n   <g id=\"line2d_15\">\n    <path d=\"M 120.261271 -1 \nL 121.951256 42.632771 \nL 125.230602 96.196823 \nL 128.509933 129.106757 \nL 131.789279 148.3248 \nL 135.06861 158.510936 \nL 138.347956 162.794885 \nL 141.627302 163.282019 \nL 144.906632 161.388667 \nL 148.185978 158.065458 \nL 151.465309 153.947225 \nL 154.744655 149.454085 \nL 158.023985 144.860116 \nL 161.303331 140.340043 \nL 164.582662 136.001281 \nL 167.862008 131.905725 \nL 171.141339 128.084941 \nL 174.420685 124.550341 \nL 177.700015 121.300444 \nL 180.979361 118.325536 \nL 184.258692 115.611176 \nL 187.538038 113.140234 \nL 190.817368 110.894545 \nL 194.096714 108.855763 \nL 197.376045 107.006039 \nL 200.655391 105.3284 \nL 203.934722 103.806924 \nL 207.214068 102.426868 \nL 210.493398 101.174715 \nL 213.772744 100.038082 \nL 217.05209 99.005751 \nL 220.331436 98.067552 \nL 223.610767 97.214305 \nL 226.890113 96.437714 \nL 230.169443 95.730341 \nL 233.448789 95.085473 \nL 236.72812 94.497083 \nL 240.007466 93.959749 \nL 243.286797 93.468618 \nL 246.566143 93.019305 \nL 249.845473 92.607883 \nL 253.124819 92.23082 \nL 256.40415 91.884933 \nL 259.683496 91.567364 \nL 262.962842 91.275531 \nL 266.242157 91.007118 \nL 269.521503 90.760026 \nL 272.800849 90.532365 \nL 276.080195 90.32243 \nL 279.35951 90.128679 \nL 282.638856 89.949711 \nL 285.918202 89.784265 \nL 289.197548 89.631197 \nL 292.476863 89.489467 \nL 295.756209 89.358132 \nL 299.035555 89.236336 \nL 302.314901 89.123302 \nL 305.594216 89.018319 \nL 308.873562 88.920743 \nL 312.152908 88.829986 \nL 315.432255 88.74551 \nL 318.71157 88.666828 \nL 321.990916 88.593491 \nL 325.270262 88.525089 \nL 328.549608 88.461247 \nL 331.828923 88.401625 \nL 335.108269 88.345905 \nL 338.387615 88.293801 \nL 341.666961 88.245048 \nL 344.946276 88.199402 \nL 348.225653 88.156638 \nL 351.504999 88.116553 \nL 354.784345 88.078956 \nL 358.06366 88.043673 \nL 361.343006 88.010543 \nL 364.622352 87.979416 \nL 367.901698 87.950157 \nL 371.181013 87.922638 \nL 374.460359 87.896743 \nL 377.739674 87.872363 \nL 381.01902 87.849397 \nL 384.298366 87.827754 \n\" clip-path=\"url(#pb2608a921a)\" style=\"fill: none; stroke: #4c72b0; stroke-width: 1.5; stroke-linecap: round\"/>\n   </g>\n   <g id=\"line2d_16\">\n    <path d=\"M 138.256376 -1 \nL 138.347956 4.2101 \nL 141.627302 122.82767 \nL 144.906632 195.770913 \nL 148.185978 238.124673 \nL 151.465309 260.133608 \nL 154.744655 268.766856 \nL 158.023985 268.765769 \nL 161.303331 263.351247 \nL 164.582662 254.702826 \nL 167.862008 244.285257 \nL 171.141339 233.072691 \nL 174.420685 221.701973 \nL 177.700015 210.579084 \nL 180.979361 199.952034 \nL 184.258692 189.962173 \nL 187.538038 180.678766 \nL 190.817368 172.123765 \nL 194.096714 164.288215 \nL 197.376045 157.144208 \nL 200.655391 150.652536 \nL 203.934722 144.768105 \nL 207.214068 139.443496 \nL 210.493398 134.631431 \nL 213.772744 130.285979 \nL 217.05209 126.363776 \nL 220.331436 122.824273 \nL 223.610767 119.630091 \nL 226.890113 116.746931 \nL 230.169443 114.143667 \nL 233.448789 111.792039 \nL 236.72812 109.666572 \nL 240.007466 107.744304 \nL 243.286797 106.004646 \nL 246.566143 104.429081 \nL 249.845473 103.001042 \nL 253.124819 101.705669 \nL 256.40415 100.529675 \nL 259.683496 99.461152 \nL 262.962842 98.489455 \nL 266.242157 97.60505 \nL 269.521503 96.799385 \nL 272.800849 96.064815 \nL 276.080195 95.394484 \nL 279.35951 94.782247 \nL 282.638856 94.222573 \nL 285.918202 93.710517 \nL 289.197548 93.241626 \nL 292.476863 92.811901 \nL 295.756209 92.417733 \nL 299.035555 92.055885 \nL 302.314901 91.723433 \nL 305.594216 91.417745 \nL 308.873562 91.136436 \nL 312.152908 90.877359 \nL 315.432255 90.638573 \nL 318.71157 90.41832 \nL 321.990916 90.215005 \nL 325.270262 90.027187 \nL 328.549608 89.853556 \nL 331.828923 89.692927 \nL 335.108269 89.544217 \nL 338.387615 89.406446 \nL 341.666961 89.278722 \nL 344.946276 89.160232 \nL 348.225653 89.050231 \nL 351.504999 88.948047 \nL 354.784345 88.853062 \nL 358.06366 88.764713 \nL 361.343006 88.682483 \nL 364.622352 88.605902 \nL 367.901698 88.534537 \nL 371.181013 88.467994 \nL 374.460359 88.40591 \nL 377.739674 88.347954 \nL 381.01902 88.293817 \nL 384.298366 88.243222 \n\" clip-path=\"url(#pb2608a921a)\" style=\"fill: none; stroke: #dd8452; stroke-width: 1.5; stroke-linecap: round\"/>\n   </g>\n   <g id=\"line2d_17\">\n    <path d=\"M 140.477874 277.491141 \nL 140.477874 11.379141 \n\" clip-path=\"url(#pb2608a921a)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #7f7f7f; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 43.411094 277.491141 \nL 43.411094 11.379141 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 400.531094 277.491141 \nL 400.531094 11.379141 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 43.411094 277.491141 \nL 400.531094 277.491141 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 43.411094 11.379141 \nL 400.531094 11.379141 \n\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pb2608a921a\">\n   <rect x=\"43.411094\" y=\"11.379141\" width=\"357.12\" height=\"266.112\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r = torch.linspace(0.5, 3, 100)\n",
    "V = lennard_jones(r)\n",
    "F = -dlj_dr(r)\n",
    "sns.lineplot(x=r, y=V)\n",
    "sns.lineplot(x=r, y=F)\n",
    "plt.ylim(-2.5, 1)\n",
    "plt.gca().axvline(x=2.0 ** (1 / 6), ls=\"--\", c=\"tab:grey\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F_autograd = -vmap(grad(lennard_jones))(r)\n",
    "torch.allclose(F_autograd, F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functorch.compile import print_compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "def forward(self, primals_1):\n",
      "    _tensor_constant0 = self._tensor_constant0\n",
      "    lift_fresh_copy = torch.ops.aten.lift_fresh_copy.default(_tensor_constant0);  _tensor_constant0 = None\n",
      "    _tensor_constant1 = self._tensor_constant1\n",
      "    lift_fresh_copy_1 = torch.ops.aten.lift_fresh_copy.default(_tensor_constant1);  _tensor_constant1 = None\n",
      "    div = torch.ops.aten.div.Tensor(lift_fresh_copy, primals_1)\n",
      "    pow_1 = torch.ops.aten.pow.Tensor_Scalar(div, 2)\n",
      "    mul = torch.ops.aten.mul.Tensor(pow_1, pow_1)\n",
      "    mul_1 = torch.ops.aten.mul.Tensor(mul, pow_1)\n",
      "    _tensor_constant2 = self._tensor_constant2\n",
      "    lift_fresh_copy_2 = torch.ops.aten.lift_fresh_copy.default(_tensor_constant2);  _tensor_constant2 = None\n",
      "    mul_2 = torch.ops.aten.mul.Tensor(lift_fresh_copy_2, lift_fresh_copy_1);  lift_fresh_copy_2 = lift_fresh_copy_1 = None\n",
      "    mul_3 = torch.ops.aten.mul.Tensor(mul_1, mul_1)\n",
      "    sub = torch.ops.aten.sub.Tensor(mul_3, mul_1);  mul_3 = None\n",
      "    mul_4 = torch.ops.aten.mul.Tensor(mul_2, sub);  sub = None\n",
      "    return [mul_4, div, lift_fresh_copy, primals_1, mul_2, mul, pow_1, mul_1]\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "def forward(self, div, lift_fresh_copy, primals_1, mul_2, mul, pow_1, mul_1, tangents_1):\n",
      "    mul_5 = torch.ops.aten.mul.Tensor(tangents_1, mul_2);  tangents_1 = mul_2 = None\n",
      "    neg = torch.ops.aten.neg.default(mul_5)\n",
      "    mul_6 = torch.ops.aten.mul.Tensor(mul_5, mul_1)\n",
      "    mul_7 = torch.ops.aten.mul.Tensor(mul_5, mul_1);  mul_5 = mul_1 = None\n",
      "    add = torch.ops.aten.add.Tensor(neg, mul_7);  neg = mul_7 = None\n",
      "    add_1 = torch.ops.aten.add.Tensor(add, mul_6);  add = mul_6 = None\n",
      "    mul_8 = torch.ops.aten.mul.Tensor(add_1, mul);  mul = None\n",
      "    mul_9 = torch.ops.aten.mul.Tensor(add_1, pow_1);  add_1 = None\n",
      "    mul_10 = torch.ops.aten.mul.Tensor(mul_9, pow_1)\n",
      "    mul_11 = torch.ops.aten.mul.Tensor(mul_9, pow_1);  mul_9 = pow_1 = None\n",
      "    add_2 = torch.ops.aten.add.Tensor(mul_8, mul_11);  mul_8 = mul_11 = None\n",
      "    add_3 = torch.ops.aten.add.Tensor(add_2, mul_10);  add_2 = mul_10 = None\n",
      "    pow_2 = torch.ops.aten.pow.Tensor_Scalar(div, 1.0);  div = None\n",
      "    mul_12 = torch.ops.aten.mul.Scalar(pow_2, 2.0);  pow_2 = None\n",
      "    mul_13 = torch.ops.aten.mul.Tensor(add_3, mul_12);  add_3 = mul_12 = None\n",
      "    div_1 = torch.ops.aten.div.Tensor(lift_fresh_copy, primals_1);  lift_fresh_copy = None\n",
      "    div_2 = torch.ops.aten.div.Tensor(div_1, primals_1);  div_1 = primals_1 = None\n",
      "    neg_1 = torch.ops.aten.neg.default(mul_13);  mul_13 = None\n",
      "    mul_14 = torch.ops.aten.mul.Tensor(neg_1, div_2);  neg_1 = div_2 = None\n",
      "    return [mul_14]\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "b = aot_function(lennard_jones, fw_compiler=print_compile, bw_compiler=print_compile)\n",
    "x = torch.linspace(0, 4, 10, requires_grad=True)\n",
    "y = b(x)\n",
    "y.sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "function"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "def forward(self, primals_1, primals_2):\n",
      "    index_select = torch.ops.aten.index_select.default(primals_1, 0, primals_2);  primals_1 = None\n",
      "    return [index_select, primals_2]\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "def forward(self, primals_2, tangents_1):\n",
      "    new_zeros = torch.ops.aten.new_zeros.default(tangents_1, [5, 4], dtype = torch.float32, layout = torch.strided, device = device(type='cpu'))\n",
      "    index_add = torch.ops.aten.index_add.default(new_zeros, 0, primals_2, tangents_1);  new_zeros = primals_2 = tangents_1 = None\n",
      "    return [index_add, None]\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "def gather(x, index):\n",
    "    return x.index_select(0, index)\n",
    "\n",
    "\n",
    "b = aot_function(gather, fw_compiler=print_compile, bw_compiler=print_compile)\n",
    "\n",
    "x = torch.randn(5, 4, requires_grad=True)\n",
    "index = torch.arange(5)\n",
    "\n",
    "y = b(x, index)\n",
    "y.sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def potential_and_force(r):\n",
    "    v = lennard_jones(r)\n",
    "    f = -vmap(grad(lennard_jones))(r)\n",
    "    return v, f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/hatemh/miniforge3/envs/hydronet/lib/python3.8/site-packages/functorch/_src/aot_autograd.py:255: UserWarning: Your compiler for AOTAutograd is returning a a function that doesn't take boxed arguments. Please wrap it with functorch.compile.make_boxed_func or handle the boxed arguments yourself. See https://github.com/pytorch/pytorch/pull/83137#issuecomment-1211320670 for rationale.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.0000, -0.0246, -0.0016, -0.0003],\n",
       "        grad_fn=<CompiledFunctionBackward>),\n",
       " tensor([ 2.4000e+01, -6.2944e-02, -2.6912e-03, -3.0716e-04],\n",
       "        grad_fn=<CompiledFunctionBackward>))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = aot_function(potential_and_force, fw_compiler=symbolic_trace)\n",
    "\n",
    "x = torch.linspace(1, 5, 4, requires_grad=True)\n",
    "f(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import poptorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:34:14.798] [poptorch:cpp] [trace] Setting op source to: /tmp/ipykernel_1652158/888324035.py:16\n",
      "[15:34:14.798] [poptorch:cpp] [debug] [DISPATCHER] Intercepting aten::empty_strided, device ipu:0\n",
      "[15:34:14.798] [poptorch:cpp] [trace] Created IPU tensor: id 1 impl_ 0x562007f3b320 size [4] strides 1 dtype Float\n",
      "[15:34:14.798] [poptorch:cpp] [trace] Setting op source to: /tmp/ipykernel_1652158/888324035.py:16\n",
      "[15:34:14.798] [poptorch:cpp] [trace] Adding 0x562007f3b320 to value mapper 0x56200974f7f8, JIT ir: 6\n",
      "[15:34:14.798] [poptorch:cpp] [debug] [DISPATCHER] Intercepting aten::copy_\n",
      "[15:34:14.798] [poptorch:cpp] [trace] [Input] self impl_ 0x562007f3b320 type ipu ID 1 sizes [4] dtype float\n",
      "[15:34:14.798] [poptorch:cpp] [trace] [Input] src impl_ 0x562009730780 type cpu sizes [4] dtype float\n",
      "[15:34:14.799] [poptorch:cpp] [trace] Setting op source to: /tmp/ipykernel_1652158/888324035.py:16\n",
      "[15:34:14.799] [poptorch:cpp] [trace] [DISPATCHER] Copying from CPU tensor 0x562009730780 with data_ptr 0x56200970c500\n",
      "[15:34:14.799] [poptorch:cpp] [trace] [DISPATCHER] Adding input: Value 0x56200975b790 with cpu ptr 0x56200970c500\n",
      "[15:34:14.799] [poptorch:cpp] [trace] Tracking tensor %7\n",
      "[15:34:14.799] [poptorch:cpp] [trace] Adding 0x562007f3b320 to value mapper 0x56200974f7f8, JIT ir: 7\n",
      "[15:34:14.799] [poptorch:cpp] [debug] copy_ CPU -> IPU input, new self impl_ 0x562007f3b320 type ipu ID 1 sizes [4] dtype float\n",
      "[15:34:14.799] [poptorch:cpp] [trace] exchangeDevice: current ipu:0 new ipu:0\n",
      "[15:34:14.799] [poptorch:cpp] [debug] [DISPATCHER] Intercepting aten::empty.memory_format, device ipu:0\n",
      "[15:34:14.799] [poptorch:cpp] [trace] Created IPU tensor: id 2 impl_ 0x5620087dbff0 size [4] strides 1 dtype Float\n",
      "[15:34:14.800] [poptorch:cpp] [trace] Setting op source to: <eval_with_key>.15:6\n",
      "[15:34:14.800] [poptorch:cpp] [trace] Adding 0x5620087dbff0 to value mapper 0x56200974f7f8, JIT ir: 14\n",
      "[15:34:14.800] [poptorch:cpp] [debug] [DISPATCHER] Intercepting aten::div.out(Tensor self, Tensor other, *, Tensor(a!) out) -> Tensor(a!) \n",
      "[15:34:14.800] [poptorch:cpp] [trace] Setting op source to: <eval_with_key>.15:6\n",
      "[15:34:14.800] [poptorch:cpp] [trace] [Input aten::div] impl_ 0x5620080f4e00 type cpu sizes [] dtype float\n",
      "[15:34:14.800] [poptorch:cpp] [trace] [Input aten::div] impl_ 0x562007f3b320 type ipu ID 1 sizes [4] dtype float\n",
      "[15:34:14.800] [poptorch:cpp] [trace] [Input aten::div] impl_ 0x5620087dbff0 type ipu ID 2 sizes [4] dtype float\n",
      "[15:34:14.800] [poptorch:cpp] [trace] [DISPATCHER][JIT] Looking for inplace arguments in schema aten::div.out(Tensor self, Tensor other, *, Tensor(a!) out) -> Tensor(a!)\n",
      "[15:34:14.800] [poptorch:cpp] [trace] [DISPATCHER][JIT] Found inplace argument, tensor ptr 0x5620087dbff0, tensor sizes=[4], type=Float\n",
      "[15:34:14.800] [poptorch:cpp] [trace] [DISPATCHER] Tensor input: tensor ptr 0x5620080f4e00 (sizes=[], type=Float), jit ir %15 (scalar type Float)\n",
      "[15:34:14.800] [poptorch:cpp] [trace] [DISPATCHER] Tensor input: tensor ptr 0x562007f3b320 (sizes=[4], type=Float), jit ir %7 (scalar type Float)\n",
      "[15:34:14.800] [poptorch:cpp] [trace] [DISPATCHER] Tensor input: tensor ptr 0x5620087dbff0 (sizes=[4], type=Float), jit ir %14 (scalar type Float)\n",
      "[15:34:14.800] [poptorch:cpp] [trace] [DISPATCHER][JIT] Node from schema %16 : Tensor = aten::div(%15, %7, %14) # <eval_with_key>.15:6:0\n",
      "\n",
      "[15:34:16.066] [poptorch:cpp] [trace] Full error: Expected an IPU tensor but got tensor(device=cpu, shape=[], dtype=Float).\n",
      "Constant tensors should be moved explicitly to the IPU, via cpu_tensor.to(\"ipu\").\n",
      "Stacktrace:\n",
      " 0# poptorch::TypeInferenceHandler::createMetaStack(std::vector<c10::IValue, std::allocator<c10::IValue> > const&, std::basic_string_view<char, std::char_traits<char> >, bool) at /opt/jenkins/workspace/poptorch/poptorch_ci_ubuntu_20_04/unprivileged/poptorch/poptorch/source/dispatch_tracer/TypeInferenceHandler.cpp:56\n",
      " 1# poptorch::TypeInferenceHandler::inferOutputTypes(c10::OperatorHandle const&, std::vector<c10::IValue, std::allocator<c10::IValue> >*) at /opt/jenkins/workspace/poptorch/poptorch_ci_ubuntu_20_04/unprivileged/poptorch/poptorch/source/dispatch_tracer/TypeInferenceHandler.cpp:26\n",
      " 2# poptorch::JITDispatch::fallback(c10::OperatorHandle const&, std::vector<c10::IValue, std::allocator<c10::IValue> >*) at /opt/jenkins/workspace/poptorch/poptorch_ci_ubuntu_20_04/unprivileged/poptorch/poptorch/source/dispatch_tracer/dispatchers/JitDispatch.cpp:382\n",
      " 3# poptorch::fallback(c10::OperatorHandle const&, std::vector<c10::IValue, std::allocator<c10::IValue> >*) at /opt/jenkins/workspace/poptorch/poptorch_ci_ubuntu_20_04/unprivileged/poptorch/poptorch/source/dispatch_tracer/RegisterAtenOverloads.cpp:470\n",
      " 4# void c10::BoxedKernel::make_boxed_function<&PoptorchCatchWrapperImpl<&poptorch::throwPoptorchError, false, void (*)(c10::OperatorHandle const&, std::vector<c10::IValue, std::allocator<c10::IValue> >*), &poptorch::fallback>::wrap>(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) at buildenv/lib/python3.8/site-packages/torch/include/ATen/core/boxing/BoxedKernel_impl.h:20\n",
      " 5# c10::impl::BoxedKernelWrapper<at::Tensor& (at::Tensor const&, at::Tensor const&, at::Tensor&), void>::call(c10::BoxedKernel const&, c10::OperatorHandle const&, c10::DispatchKeySet, at::Tensor const&, at::Tensor const&, at::Tensor&) in /nethome/hatemh/miniforge3/envs/hydronet/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so\n",
      " 6# at::_ops::div_out::call(at::Tensor const&, at::Tensor const&, at::Tensor&) in /nethome/hatemh/miniforge3/envs/hydronet/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so\n",
      " 7# at::(anonymous namespace)::wrapper_div_Tensor(at::Tensor const&, at::Tensor const&) in /nethome/hatemh/miniforge3/envs/hydronet/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so\n",
      " 8# c10::impl::wrap_kernel_functor_unboxed_<c10::impl::detail::WrapFunctionIntoFunctor_<c10::CompileTimeFunctionPointer<at::Tensor (at::Tensor const&, at::Tensor const&), &at::(anonymous namespace)::wrapper_div_Tensor>, at::Tensor, c10::guts::typelist::typelist<at::Tensor const&, at::Tensor const&> >, at::Tensor (at::Tensor const&, at::Tensor const&)>::call(c10::OperatorKernel*, c10::DispatchKeySet, at::Tensor const&, at::Tensor const&) in /nethome/hatemh/miniforge3/envs/hydronet/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so\n",
      " 9# at::_ops::div_Tensor::redispatch(c10::DispatchKeySet, at::Tensor const&, at::Tensor const&) in /nethome/hatemh/miniforge3/envs/hydronet/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so\n",
      "10# torch::autograd::VariableType::(anonymous namespace)::div_Tensor(c10::DispatchKeySet, at::Tensor const&, at::Tensor const&) in /nethome/hatemh/miniforge3/envs/hydronet/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so\n",
      "11# c10::impl::make_boxed_from_unboxed_functor<c10::impl::detail::WrapFunctionIntoFunctor_<c10::CompileTimeFunctionPointer<at::Tensor (c10::DispatchKeySet, at::Tensor const&, at::Tensor const&), &torch::autograd::VariableType::(anonymous namespace)::div_Tensor>, at::Tensor, c10::guts::typelist::typelist<c10::DispatchKeySet, at::Tensor const&, at::Tensor const&> >, false>::call(c10::OperatorKernel*, c10::OperatorHandle const&, c10::DispatchKeySet, std::vector<c10::IValue, std::allocator<c10::IValue> >*) in /nethome/hatemh/miniforge3/envs/hydronet/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so\n",
      "12# c10::Dispatcher::callBoxed(c10::OperatorHandle const&, std::vector<c10::IValue, std::allocator<c10::IValue> >*) const in /nethome/hatemh/miniforge3/envs/hydronet/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so\n",
      "13# torch::jit::invokeOperatorFromPython(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, pybind11::args, pybind11::kwargs const&, c10::optional<c10::DispatchKey>) in /nethome/hatemh/miniforge3/envs/hydronet/lib/python3.8/site-packages/torch/lib/libtorch_python.so\n",
      "14# torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args, pybind11::kwargs const&, bool, c10::optional<c10::DispatchKey>) in /nethome/hatemh/miniforge3/envs/hydronet/lib/python3.8/site-packages/torch/lib/libtorch_python.so\n",
      "15# pybind11::cpp_function::initialize<torch::jit::initJITBindings(_object*)::{lambda(std::string const&, std::string const&)#191}::operator()(std::string const&, std::string const&) const::{lambda(pybind11::args, pybind11::kwargs)#1}, pybind11::object, pybind11::args, pybind11::kwargs>(torch::jit::initJITBindings(_object*)::{lambda(std::string const&, std::string const&)#191}::operator()(std::string const&, std::string const&) const::{lambda(pybind11::args, pybind11::kwargs)#1}&&, pybind11::object (*)(pybind11::args, pybind11::kwargs))::{lambda(pybind11::detail::function_call&)#3}::_FUN(pybind11::detail::function_call&) in /nethome/hatemh/miniforge3/envs/hydronet/lib/python3.8/site-packages/torch/lib/libtorch_python.so\n",
      "16# pybind11::cpp_function::dispatcher(_object*, _object*, _object*) in /nethome/hatemh/miniforge3/envs/hydronet/lib/python3.8/site-packages/torch/lib/libtorch_python.so\n",
      "17# PyCFunction_Call at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Objects/call.c:773\n",
      "18# _PyEval_EvalFrameDefault at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Python/ceval.c:3559\n",
      "19# _PyEval_EvalCodeWithName at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Python/ceval.c:4298\n",
      "20# _PyObject_FastCallDict at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Objects/call.c:96\n",
      "21# _PyObject_Call_Prepend at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Objects/call.c:895\n",
      "22# slot_tp_call at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Objects/typeobject.c:6562\n",
      "23# _PyObject_MakeTpCall at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Objects/call.c:159\n",
      "24# _PyEval_EvalFrameDefault at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Python/ceval.c:3469\n",
      "25# _PyFunction_Vectorcall at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Objects/call.c:411\n",
      "26# method_vectorcall at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Objects/classobject.c:89\n",
      "27# PyObject_Call at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Objects/call.c:228\n",
      "28# _PyEval_EvalFrameDefault at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Python/ceval.c:3559\n",
      "29# _PyEval_EvalCodeWithName at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Python/ceval.c:4298\n",
      "30# _PyFunction_Vectorcall at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Objects/call.c:436\n",
      "31# method_vectorcall at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Objects/classobject.c:89\n",
      "32# PyObject_Call at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Objects/call.c:228\n",
      "33# _PyEval_EvalFrameDefault at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Python/ceval.c:3559\n",
      "34# _PyEval_EvalCodeWithName at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Python/ceval.c:4298\n",
      "35# _PyFunction_Vectorcall at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Objects/call.c:436\n",
      "36# _PyObject_FastCallDict at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Objects/call.c:105\n",
      "37# _PyObject_Call_Prepend at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Objects/call.c:895\n",
      "38# slot_tp_call at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Objects/typeobject.c:6562\n",
      "39# PyObject_Call at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Objects/call.c:248\n",
      "40# _PyEval_EvalFrameDefault at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Python/ceval.c:3559\n",
      "41# _PyEval_EvalCodeWithName at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Python/ceval.c:4298\n",
      "42# _PyObject_FastCallDict at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Objects/call.c:96\n",
      "43# _PyObject_Call_Prepend at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Objects/call.c:895\n",
      "44# slot_tp_call at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Objects/typeobject.c:6562\n",
      "45# PyObject_Call at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Objects/call.c:248\n",
      "46# _PyEval_EvalFrameDefault at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Python/ceval.c:3559\n",
      "47# _PyEval_EvalCodeWithName at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Python/ceval.c:4298\n",
      "48# _PyFunction_Vectorcall at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Objects/call.c:436\n",
      "49# _PyEval_EvalFrameDefault at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Python/ceval.c:3500\n",
      "50# _PyEval_EvalCodeWithName at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Python/ceval.c:4298\n",
      "51# _PyFunction_Vectorcall at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Objects/call.c:436\n",
      "52# PyObject_CallObject at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Objects/call.c:818\n",
      "53# THPFunction_apply(_object*, _object*) in /nethome/hatemh/miniforge3/envs/hydronet/lib/python3.8/site-packages/torch/lib/libtorch_python.so\n",
      "54# PyCFunction_Call at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Objects/call.c:773\n",
      "55# _PyEval_EvalFrameDefault at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Python/ceval.c:3559\n",
      "56# _PyEval_EvalCodeWithName at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Python/ceval.c:4298\n",
      "57# _PyFunction_Vectorcall at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Objects/call.c:436\n",
      "58# PyObject_Call at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Objects/call.c:228\n",
      "59# _PyEval_EvalFrameDefault at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Python/ceval.c:3559\n",
      "60# _PyEval_EvalCodeWithName at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Python/ceval.c:4298\n",
      "61# _PyFunction_Vectorcall at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Objects/call.c:436\n",
      "62# _PyEval_EvalFrameDefault at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Python/ceval.c:3500\n",
      "63# _PyEval_EvalCodeWithName at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Python/ceval.c:4298\n",
      "64# _PyFunction_Vectorcall at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Objects/call.c:436\n",
      "65# _PyEval_EvalFrameDefault at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Python/ceval.c:3469\n",
      "66# _PyFunction_Vectorcall at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Objects/call.c:411\n",
      "67# method_vectorcall at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Objects/classobject.c:89\n",
      "68# PyObject_Call at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Objects/call.c:228\n",
      "69# _PyEval_EvalFrameDefault at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Python/ceval.c:3559\n",
      "70# _PyEval_EvalCodeWithName at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Python/ceval.c:4298\n",
      "71# _PyFunction_Vectorcall at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Objects/call.c:436\n",
      "72# _PyObject_FastCallDict at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Objects/call.c:105\n",
      "73# _PyObject_Call_Prepend at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Objects/call.c:895\n",
      "74# slot_tp_call at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Objects/typeobject.c:6562\n",
      "75# PyObject_Call at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Objects/call.c:248\n",
      "76# _PyEval_EvalFrameDefault at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Python/ceval.c:3559\n",
      "77# _PyEval_EvalCodeWithName at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Python/ceval.c:4298\n",
      "78# _PyFunction_Vectorcall at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Objects/call.c:436\n",
      "79# PyObject_Call at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Objects/call.c:228\n",
      "80# _PyEval_EvalFrameDefault at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Python/ceval.c:3559\n",
      "81# _PyEval_EvalCodeWithName at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Python/ceval.c:4298\n",
      "82# method_vectorcall at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Objects/classobject.c:60\n",
      "83# _PyEval_EvalFrameDefault at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Python/ceval.c:3469\n",
      "84# _PyFunction_Vectorcall at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Objects/call.c:411\n",
      "85# PyObject_Call at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Objects/call.c:228\n",
      "86# _PyEval_EvalFrameDefault at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Python/ceval.c:3559\n",
      "87# _PyEval_EvalCodeWithName at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Python/ceval.c:4298\n",
      "88# method_vectorcall at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Objects/classobject.c:60\n",
      "89# _PyEval_EvalFrameDefault at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Python/ceval.c:3469\n",
      "90# _PyEval_EvalCodeWithName at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Python/ceval.c:4298\n",
      "91# _PyObject_FastCallDict at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Objects/call.c:96\n",
      "92# _PyObject_Call_Prepend at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Objects/call.c:895\n",
      "93# slot_tp_call at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Objects/typeobject.c:6562\n",
      "94# _PyObject_MakeTpCall at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Objects/call.c:159\n",
      "95# _PyEval_EvalFrameDefault at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Python/ceval.c:3500\n",
      "96# _PyEval_EvalCodeWithName at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Python/ceval.c:4298\n",
      "97# PyEval_EvalCodeEx at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Python/ceval.c:4334\n",
      "98# PyEval_EvalCode at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Python/ceval.c:724\n",
      "99# builtin_exec at /home/conda/feedstock_root/build_artifacts/python-split_1631566923692/work/Python/clinic/bltinmodule.c.h:396\n",
      "\n",
      "[15:34:16.070] [poptorch:cpp] [trace] uncheckedSetDevice: current ipu:0 new ipu:0\n"
     ]
    },
    {
     "ename": "Error",
     "evalue": "In poptorch/source/dispatch_tracer/TypeInferenceHandler.cpp:123: 'poptorch_cpp_error': Expected an IPU tensor but got tensor(device=cpu, shape=[], dtype=Float).\nConstant tensors should be moved explicitly to the IPU, via cpu_tensor.to(\"ipu\").",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m m \u001b[39m=\u001b[39m poptorch\u001b[39m.\u001b[39minferenceModel(m, opts)\n\u001b[1;32m     15\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mlinspace(\u001b[39m1\u001b[39m, \u001b[39m5\u001b[39m, \u001b[39m4\u001b[39m, requires_grad\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m---> 16\u001b[0m m(x)\n",
      "File \u001b[0;32m~/miniforge3/envs/hydronet/lib/python3.8/site-packages/poptorch/_poplar_executor.py:1151\u001b[0m, in \u001b[0;36mPoplarExecutor.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1148\u001b[0m in_tensors \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_args_parser(args, kwargs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39misCompiled())\n\u001b[1;32m   1150\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39misCompiled():\n\u001b[0;32m-> 1151\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compile(in_tensors)\n\u001b[1;32m   1153\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_attached:\n\u001b[1;32m   1154\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattachToDevice()\n",
      "File \u001b[0;32m~/miniforge3/envs/hydronet/lib/python3.8/site-packages/poptorch/_impl.py:358\u001b[0m, in \u001b[0;36mtraceMethod.<locals>.decorator.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[1;32m    356\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    357\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_profiling\u001b[39m.\u001b[39mtracepoint(label):  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m--> 358\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/hydronet/lib/python3.8/site-packages/poptorch/_poplar_executor.py:911\u001b[0m, in \u001b[0;36mPoplarExecutor._compile\u001b[0;34m(self, in_tensors)\u001b[0m\n\u001b[1;32m    907\u001b[0m \u001b[39m# In distributed execution mode:\u001b[39;00m\n\u001b[1;32m    908\u001b[0m \u001b[39m# At that point only the first process will have a compiled executable:\u001b[39;00m\n\u001b[1;32m    909\u001b[0m \u001b[39m# trigger the compilation process in all the other processes.\u001b[39;00m\n\u001b[1;32m    910\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39misCompiled():\n\u001b[0;32m--> 911\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_executable \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compileWithDispatch(in_tensors_trace_view)\n\u001b[1;32m    913\u001b[0m \u001b[39m# Load the engine and connect the streams in all the processes.\u001b[39;00m\n\u001b[1;32m    914\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m    915\u001b[0m \u001b[39m# Note: no sync point was added because we expect the above\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[39m# to enable executable caching to avoid out of memory issues due\u001b[39;00m\n\u001b[1;32m    924\u001b[0m \u001b[39m# to concurrent compilation processes.\u001b[39;00m\n\u001b[1;32m    925\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_options\u001b[39m.\u001b[39mconnection_type \u001b[39m!=\u001b[39m enums\u001b[39m.\u001b[39mConnectionType\u001b[39m.\u001b[39mNever:\n",
      "File \u001b[0;32m~/miniforge3/envs/hydronet/lib/python3.8/site-packages/poptorch/_impl.py:164\u001b[0m, in \u001b[0;36mdestroyDispatcherOnExit.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[1;32m    162\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    163\u001b[0m     \u001b[39mwith\u001b[39;00m OnExit():\n\u001b[0;32m--> 164\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/hydronet/lib/python3.8/site-packages/poptorch/_poplar_executor.py:787\u001b[0m, in \u001b[0;36mPoplarExecutor._compileWithDispatch\u001b[0;34m(self, in_tensors, executable_filename)\u001b[0m\n\u001b[1;32m    783\u001b[0m \u001b[39m# Re-inject moved tensors in args and kwargs:\u001b[39;00m\n\u001b[1;32m    784\u001b[0m args, kwargs \u001b[39m=\u001b[39m reconstructTensorStructure(\n\u001b[1;32m    785\u001b[0m     (in_tensors\u001b[39m.\u001b[39margs, in_tensors\u001b[39m.\u001b[39mkwargs), tensor_args)\n\u001b[0;32m--> 787\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_model(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    788\u001b[0m \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    789\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_outputs_structure \u001b[39m=\u001b[39m result\n",
      "File \u001b[0;32m~/miniforge3/envs/hydronet/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[12], line 7\u001b[0m, in \u001b[0;36mmodule.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m----> 7\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(x)\n",
      "File \u001b[0;32m~/miniforge3/envs/hydronet/lib/python3.8/site-packages/functorch/_src/aot_autograd.py:664\u001b[0m, in \u001b[0;36maot_function.<locals>.returned_function\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    661\u001b[0m     cached_res \u001b[39m=\u001b[39m (compiled_fn, out_spec)\n\u001b[1;32m    663\u001b[0m cached_fn, out_spec \u001b[39m=\u001b[39m cached_res\n\u001b[0;32m--> 664\u001b[0m out \u001b[39m=\u001b[39m cached_fn(flat_args)\n\u001b[1;32m    665\u001b[0m \u001b[39mreturn\u001b[39;00m out_spec\u001b[39m.\u001b[39munflatten(out)\n",
      "File \u001b[0;32m~/miniforge3/envs/hydronet/lib/python3.8/site-packages/functorch/_src/aot_autograd.py:229\u001b[0m, in \u001b[0;36mmake_boxed_func.<locals>.g\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mg\u001b[39m(args):\n\u001b[0;32m--> 229\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[0;32m~/miniforge3/envs/hydronet/lib/python3.8/site-packages/functorch/_src/aot_autograd.py:434\u001b[0m, in \u001b[0;36maot_dispatch_autograd.<locals>.compiled_function\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[39m@wraps\u001b[39m(CompiledFunction\u001b[39m.\u001b[39mapply)\n\u001b[1;32m    433\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompiled_function\u001b[39m(\u001b[39m*\u001b[39margs):\n\u001b[0;32m--> 434\u001b[0m     \u001b[39mreturn\u001b[39;00m CompiledFunction\u001b[39m.\u001b[39;49mapply(\u001b[39m*\u001b[39;49mremove_dupe_args(args))\n",
      "File \u001b[0;32m~/miniforge3/envs/hydronet/lib/python3.8/site-packages/functorch/_src/aot_autograd.py:408\u001b[0m, in \u001b[0;36maot_dispatch_autograd.<locals>.CompiledFunction.forward\u001b[0;34m(ctx, *deduped_flat_tensor_args)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    406\u001b[0m \u001b[39m@disable_torchdynamo\u001b[39m\n\u001b[1;32m    407\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(ctx, \u001b[39m*\u001b[39mdeduped_flat_tensor_args):\n\u001b[0;32m--> 408\u001b[0m     fw_outs \u001b[39m=\u001b[39m call_func_with_args(\n\u001b[1;32m    409\u001b[0m         CompiledFunction\u001b[39m.\u001b[39;49mcompiled_fw, deduped_flat_tensor_args\n\u001b[1;32m    410\u001b[0m     )\n\u001b[1;32m    411\u001b[0m     num_outs \u001b[39m=\u001b[39m CompiledFunction\u001b[39m.\u001b[39mnum_outs\n\u001b[1;32m    412\u001b[0m     ctx\u001b[39m.\u001b[39msave_for_backward(\u001b[39m*\u001b[39mfw_outs[num_outs:])\n",
      "File \u001b[0;32m~/miniforge3/envs/hydronet/lib/python3.8/site-packages/functorch/_src/aot_autograd.py:260\u001b[0m, in \u001b[0;36mcall_func_with_args\u001b[0;34m(f, args, steal_args)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    253\u001b[0m     \u001b[39m# TODO: Please remove soon\u001b[39;00m\n\u001b[1;32m    254\u001b[0m     \u001b[39m# https://github.com/pytorch/pytorch/pull/83137#issuecomment-1211320670\u001b[39;00m\n\u001b[1;32m    255\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    256\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYour compiler for AOTAutograd is returning a a function that doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt take boxed arguments. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    257\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease wrap it with functorch.compile.make_boxed_func or handle the boxed arguments yourself. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    258\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mSee https://github.com/pytorch/pytorch/pull/83137#issuecomment-1211320670 for rationale.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    259\u001b[0m     )\n\u001b[0;32m--> 260\u001b[0m     out \u001b[39m=\u001b[39m normalize_as_list(f(\u001b[39m*\u001b[39;49margs))\n\u001b[1;32m    261\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/miniforge3/envs/hydronet/lib/python3.8/site-packages/torch/fx/graph_module.py:658\u001b[0m, in \u001b[0;36mGraphModule.recompile.<locals>.call_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall_wrapped\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 658\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wrapped_call(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/hydronet/lib/python3.8/site-packages/torch/fx/graph_module.py:277\u001b[0m, in \u001b[0;36m_WrappedCall.__call__\u001b[0;34m(self, obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    276\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 277\u001b[0m     \u001b[39mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/miniforge3/envs/hydronet/lib/python3.8/site-packages/torch/fx/graph_module.py:267\u001b[0m, in \u001b[0;36m_WrappedCall.__call__\u001b[0;34m(self, obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcls_call(obj, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    266\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 267\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcls, obj)\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    268\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    269\u001b[0m     \u001b[39massert\u001b[39;00m e\u001b[39m.\u001b[39m__traceback__\n",
      "File \u001b[0;32m~/miniforge3/envs/hydronet/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m<eval_with_key>.15:6\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(self, primals_1)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, primals_1):\n\u001b[1;32m      5\u001b[0m     _tensor_constant6 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tensor_constant6\n\u001b[0;32m----> 6\u001b[0m     div_tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mops\u001b[39m.\u001b[39;49maten\u001b[39m.\u001b[39;49mdiv\u001b[39m.\u001b[39;49mTensor(_tensor_constant6, primals_1);  _tensor_constant6 \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     pow_tensor_scalar \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39maten\u001b[39m.\u001b[39mpow\u001b[39m.\u001b[39mTensor_Scalar(div_tensor, \u001b[39m2\u001b[39m)\n\u001b[1;32m      8\u001b[0m     mul_tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39maten\u001b[39m.\u001b[39mmul\u001b[39m.\u001b[39mTensor(pow_tensor_scalar, pow_tensor_scalar)\n",
      "File \u001b[0;32m~/miniforge3/envs/hydronet/lib/python3.8/site-packages/torch/_ops.py:257\u001b[0m, in \u001b[0;36mOpOverload.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 257\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_op(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs \u001b[39mor\u001b[39;49;00m {})\n",
      "\u001b[0;31mError\u001b[0m: In poptorch/source/dispatch_tracer/TypeInferenceHandler.cpp:123: 'poptorch_cpp_error': Expected an IPU tensor but got tensor(device=cpu, shape=[], dtype=Float).\nConstant tensors should be moved explicitly to the IPU, via cpu_tensor.to(\"ipu\")."
     ]
    }
   ],
   "source": [
    "class module(torch.nn.Module):\n",
    "    def __init__(self, func) -> None:\n",
    "        super().__init__()\n",
    "        self.model = func\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "poptorch.setLogLevel(0)\n",
    "m = module(f)\n",
    "opts = poptorch.Options()\n",
    "opts.useIpuModel(True)\n",
    "m = poptorch.inferenceModel(m, opts)\n",
    "x = torch.linspace(1, 5, 4, requires_grad=False)\n",
    "m(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hydronet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
